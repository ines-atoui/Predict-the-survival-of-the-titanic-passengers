# -*- coding: utf-8 -*-
"""predicts the survival of  Titanic passengers

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1xlV6B_t_fGIyQ1g6o9vRMsIBpzrRQYFL
"""

import pandas as pd
import numpy as np
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn import metrics
titanic=pd.read_csv("titanic-passengers (1).csv", sep=';')
titanic.info()
titanic.describe()

titanic.groupby(['Survived']).count()

"""#Cleaning our dataset"""

titanic.isnull().sum()

titanic.drop(columns=['Name','Ticket','PassengerId','Cabin','Embarked'],inplace=True)
titanic['Age'].fillna(titanic['Age'].mean(), inplace=True)
titanic["Survived"]=titanic["Survived"].map({"Yes": 1, "No": 0})
titanic["Sex"]=titanic["Sex"].map({"female": 1, "male": 0})
titanic

"""# Logistic Regression"""

X=titanic.drop(columns=['Survived'])
y=titanic['Survived']
X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.25,random_state=19)
logreg = LogisticRegression()
logreg.fit(X_train, y_train)
y_pred  = logreg.predict(X_test)
print("Accuracy={:.2f}".format(logreg.score(X_test, y_test)))

confusion_matrix = pd.crosstab(y_test, y_pred, rownames=['Actual'], colnames=['Predicted'])
sns.heatmap(confusion_matrix, annot=True)

"""ROC (Receiver Operating Characteristic) and AUC (Area Under the Curve) are tools used to evaluate the performance of a classification model.
The ROC curve is a graphical representation of the performance of a binary classifier as its discrimination threshold is varied. It plots the true positive rate (TPR) against the false positive rate (FPR) at different threshold settings. The TPR is the proportion of actual positive cases that are correctly identified as positive by the model, while the FPR is the proportion of actual negative cases that are incorrectly identified as positive by the model.

The AUC is the area under the ROC curve, which measures the degree of separability of the model's classes. A perfect classifier will have an AUC of 1, while a random classifier will have an AUC of 0.5. Therefore, the higher the AUC, the better the model's performance.
"""

from sklearn.metrics import roc_auc_score
import matplotlib.pyplot as plt

y_pred_proba = logreg.predict_proba(X_test)[::,1]
fpr, tpr, _ = metrics.roc_curve(y_test, y_pred_proba)
plt.plot(fpr,tpr)
plt.ylabel('True Positive Rate')
plt.xlabel('False Positive Rate')
plt.show()

"""#2 KNN"""

from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import accuracy_score
knn=KNeighborsClassifier(n_neighbors=20)
knn.fit(X_train,y_train)
y_pred=knn.predict(X_test)
print('Acuuracy=',accuracy_score(y_pred,y_test))

#The optimal number of neighbors
error_rate = []
for i in range(1,300):
 knn = KNeighborsClassifier(n_neighbors=i)
 knn.fit(X_train,y_train)
 pred_i = knn.predict(X_test)
 error_rate.append(np.mean(pred_i != y_test))
plt.plot(error_rate)

"""# Decision tree"""

from sklearn.tree import DecisionTreeClassifier
from sklearn import tree

decision_tree = DecisionTreeClassifier(criterion="gini",random_state=19)
decision_tree.fit(X_train, y_train)
y_pred=decision_tree.predict(X_test)
print("gini_accuracy:{}".format(accuracy_score(y_test, y_pred)))

#Plot the decision tree
fig = plt.figure(figsize=(25,20))
_=tree.plot_tree(decision_tree,
                 feature_names=["Pclass",	"Sex"	,"Age",	"SibSp"	,"Parch"	,"Fare"],
                  class_names=["0","1"],
                  filled=True)

"""The model predicts that the majority of passengers will survive because the majority of the cells in the last line are blue."""

#Changing the decision tree parameters
decision_tree = DecisionTreeClassifier(criterion="entropy",max_depth=1,random_state=19)
decision_tree.fit(X_train, y_train)
y_pred=decision_tree.predict(X_test)
print("entropy_accuracy:{}".format(accuracy_score(y_test, y_pred)))

"""**NOTE:** One notices that the accuracy improves when specific parameters are changed

#Random forest
"""

from sklearn.ensemble import RandomForestClassifier
RF=RandomForestClassifier(n_estimators=10,random_state=19)
RF.fit(X_train, y_train)
y_pred=RF.predict(X_test)
print("Accuracy:", metrics.accuracy_score(y_test, y_pred))

#Changing the number of estimators
from sklearn.ensemble import RandomForestClassifier
RF=RandomForestClassifier(n_estimators=200,random_state=19)
RF.fit(X_train, y_train)
y_pred=RF.predict(X_test)
print("Accuracy:", metrics.accuracy_score(y_test, y_pred))

"""**NOTE:** When we increase the number of estimators, we notice that accuracy decrease."""

data = {'logreg':0.78, 'knn':0.6905829596412556, 'decision_tree':0.7533632286995515,
        'RF':0.8385650224215246}
models_name  = list(data.keys())
accuracy = list(data.values())

fig = plt.figure(figsize = (10, 5))

plt.bar(models_name, accuracy, color ='green',
        width = 0.4)

plt.xlabel("models_name")
plt.ylabel("accuracy")
plt.title("a summary graph which resume all accuracies of each model")
plt.show()













